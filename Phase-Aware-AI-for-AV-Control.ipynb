{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee025dce-7e56-482e-a1d8-7a540bbc6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set environment\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "plt.switch_backend('Agg')\n",
    "\n",
    "def set_global_seed(seed=42):\n",
    "    \"\"\"Set global random seed for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Global random seed set to: {seed}\")\n",
    "\n",
    "def ensure_1d_tensor(tensor):\n",
    "    \"\"\"Ensure tensor is 1D with robust handling\"\"\"\n",
    "    if not isinstance(tensor, torch.Tensor):\n",
    "        tensor = torch.tensor(tensor, dtype=torch.float32)\n",
    "    tensor = tensor.squeeze()\n",
    "    if tensor.dim() == 0:\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "    elif tensor.dim() > 1:\n",
    "        tensor = tensor.flatten()\n",
    "    return tensor.to(dtype=torch.float32)\n",
    "\n",
    "class SpacingFocusedEarlyStopping:\n",
    "    \"\"\"Spacing-focused early stopping strategy\"\"\"\n",
    "    def __init__(self, patience=10, min_delta=1e-3, spacing_weight=0.6):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.spacing_weight = spacing_weight\n",
    "        self.best_score = float('inf')\n",
    "        self.wait = 0\n",
    "    \n",
    "    def __call__(self, val_loss, val_spacing_rmse):\n",
    "        combined_score = (1 - self.spacing_weight) * val_loss + self.spacing_weight * val_spacing_rmse\n",
    "        if combined_score < self.best_score - self.min_delta:\n",
    "            self.best_score = combined_score\n",
    "            self.wait = 0\n",
    "            return False\n",
    "        self.wait += 1\n",
    "        return self.wait >= self.patience\n",
    "\n",
    "class OVRVModel:\n",
    "    \"\"\"Optimal Velocity Relative Velocity (OVRV) model\"\"\"\n",
    "    def __init__(self, k1, k2, eta, tau):\n",
    "        self.k1, self.k2, self.eta, self.tau = k1, k2, eta, tau\n",
    "    \n",
    "    def predict_acceleration(self, spacing, follow_speed, lead_speed):\n",
    "        spacing = torch.tensor(spacing, dtype=torch.float32) if not isinstance(spacing, torch.Tensor) else spacing\n",
    "        follow_speed = torch.tensor(follow_speed, dtype=torch.float32) if not isinstance(follow_speed, torch.Tensor) else follow_speed\n",
    "        lead_speed = torch.tensor(lead_speed, dtype=torch.float32) if not isinstance(lead_speed, torch.Tensor) else lead_speed\n",
    "        \n",
    "        spacing = ensure_1d_tensor(spacing)\n",
    "        follow_speed = ensure_1d_tensor(follow_speed)\n",
    "        lead_speed = ensure_1d_tensor(lead_speed)\n",
    "        \n",
    "        acc = self.k1 * (spacing - self.eta - self.tau * follow_speed) + self.k2 * (lead_speed - follow_speed)\n",
    "        return torch.clamp(acc, -10.0, 10.0)\n",
    "\n",
    "class IDMModel:\n",
    "    \"\"\"Intelligent Driver Model (IDM)\"\"\"\n",
    "    def __init__(self, a, b, delta, s0, T, v0):\n",
    "        self.a = max(abs(a), 1e-6)\n",
    "        self.b = max(abs(b), 1e-6)\n",
    "        self.delta, self.s0, self.T, self.v0 = delta, s0, T, v0\n",
    "    \n",
    "    def predict_acceleration(self, spacing, follow_speed, lead_speed):\n",
    "        spacing = torch.tensor(spacing, dtype=torch.float32) if not isinstance(spacing, torch.Tensor) else spacing\n",
    "        follow_speed = torch.tensor(follow_speed, dtype=torch.float32) if not isinstance(follow_speed, torch.Tensor) else follow_speed\n",
    "        lead_speed = torch.tensor(lead_speed, dtype=torch.float32) if not isinstance(lead_speed, torch.Tensor) else lead_speed\n",
    "        \n",
    "        spacing = ensure_1d_tensor(spacing)\n",
    "        follow_speed = ensure_1d_tensor(follow_speed)\n",
    "        lead_speed = ensure_1d_tensor(lead_speed)\n",
    "        \n",
    "        s_star = self.s0 + follow_speed * self.T + (follow_speed * (follow_speed - lead_speed)) / (2 * torch.sqrt(torch.tensor(self.a * self.b)))\n",
    "        spacing_safe = torch.clamp(spacing, min=0.1)\n",
    "        acc = self.a * (1 - (follow_speed / self.v0) ** self.delta - (s_star / spacing_safe) ** 2)\n",
    "        return torch.clamp(acc, -10.0, 10.0)\n",
    "\n",
    "class EnhancedDataset(Dataset):\n",
    "    \"\"\"Streamlined dataset with 6D features\"\"\"\n",
    "    def __init__(self, data, traditional_model, seq_length=12, delta_t=0.02, device='cpu', \n",
    "                 noise_std=0.005, augment_prob=0.12, model_type='OVRV'):\n",
    "        self.seq_length = seq_length\n",
    "        self.delta_t = delta_t\n",
    "        self.device = device\n",
    "        self.noise_std = noise_std if model_type != 'OVRV' else 0.002\n",
    "        self.augment_prob = augment_prob if model_type != 'OVRV' else 0.08\n",
    "        self.training = False\n",
    "        \n",
    "        # Core data tensors\n",
    "        self.lead_speed = torch.tensor(data['lead_speed'].values, dtype=torch.float32, device=device)\n",
    "        self.follow_speed = torch.tensor(data['follow_speed'].values, dtype=torch.float32, device=device)\n",
    "        self.spacing = torch.tensor(data['spacing'].values, dtype=torch.float32, device=device)\n",
    "        self.actual_acc = torch.tensor(data['actual_acc'].values, dtype=torch.float32, device=device)\n",
    "        \n",
    "        # Derived features\n",
    "        self.relative_speed = self.lead_speed - self.follow_speed\n",
    "        self.base_acc = self._compute_base_predictions(traditional_model)\n",
    "        self.safety_margin = self._compute_safety_margin()\n",
    "        \n",
    "        # Prepare features for sequence modeling\n",
    "        self.next_spacing = self.spacing[1:]\n",
    "        self.current_lead_speed = self.lead_speed[:-1]\n",
    "        self.current_follow_speed = self.follow_speed[:-1]\n",
    "        self.actual_acc = self.actual_acc[:-1]\n",
    "        self.features = self._extract_features()[:-1]\n",
    "        \n",
    "        print(f\"Dataset - Size: {len(self.features)}, Features: {self.features.shape[1]}D\")\n",
    "    \n",
    "    def _compute_safety_margin(self):\n",
    "        safe_distance = 2.0 + 1.5 * torch.clamp(self.follow_speed, min=0)\n",
    "        safety_margin = (self.spacing - safe_distance) / torch.clamp(safe_distance, min=1e-6)\n",
    "        return torch.clamp(safety_margin, -5.0, 8.0)\n",
    "    \n",
    "    def _compute_base_predictions(self, model):\n",
    "        n = len(self.lead_speed)\n",
    "        base_acc = torch.zeros(n, device=self.device)\n",
    "        for i in range(n):\n",
    "            try:\n",
    "                acc = model.predict_acceleration(self.spacing[i], self.follow_speed[i], self.lead_speed[i])\n",
    "                base_acc[i] = acc.item() if acc.dim() > 0 else acc\n",
    "            except:\n",
    "                base_acc[i] = 0.0\n",
    "        return base_acc\n",
    "    \n",
    "    def _extract_features(self):\n",
    "        return torch.stack([\n",
    "            self.lead_speed, self.follow_speed, self.spacing,\n",
    "            self.relative_speed, self.safety_margin, self.base_acc\n",
    "        ], dim=1)\n",
    "    \n",
    "    def set_training(self, training):\n",
    "        self.training = training\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(0, len(self.features) - self.seq_length)\n",
    "    \n",
    "    def _augment_data(self, features):\n",
    "        if not self.training or torch.rand(1) > self.augment_prob:\n",
    "            return features\n",
    "        \n",
    "        noise_scales = torch.tensor([1.0, 1.0, 0.3, 0.8, 0.2, 0.5], device=features.device)\n",
    "        noise = torch.randn_like(features) * self.noise_std * noise_scales.unsqueeze(0)\n",
    "        augmented = features + noise\n",
    "        \n",
    "        # Constraints\n",
    "        augmented[:, 1] = torch.clamp(augmented[:, 1], min=0)  # Speed >= 0\n",
    "        augmented[:, 2] = torch.clamp(augmented[:, 2], min=0.5)  # Spacing >= 0.5\n",
    "        \n",
    "        # Recalculate derived features\n",
    "        augmented[:, 3] = augmented[:, 0] - augmented[:, 1]  # Relative speed\n",
    "        safe_distance = 2.0 + 1.5 * torch.clamp(augmented[:, 1], min=0)\n",
    "        augmented[:, 4] = torch.clamp((augmented[:, 2] - safe_distance) / torch.clamp(safe_distance, min=1e-6), -5.0, 8.0)\n",
    "        \n",
    "        return augmented\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        end_idx = idx + self.seq_length\n",
    "        features = self.features[idx:end_idx].clone()\n",
    "        features = self._augment_data(features)\n",
    "        \n",
    "        # Return batch items with proper 1D shape\n",
    "        return (\n",
    "            features,\n",
    "            ensure_1d_tensor(self.current_follow_speed[end_idx-1]).unsqueeze(0),\n",
    "            ensure_1d_tensor(self.spacing[end_idx-1]).unsqueeze(0),\n",
    "            ensure_1d_tensor(self.current_lead_speed[end_idx-1]).unsqueeze(0),\n",
    "            ensure_1d_tensor(self.next_spacing[end_idx-1]).unsqueeze(0),\n",
    "            ensure_1d_tensor(self.actual_acc[end_idx-1]).unsqueeze(0)\n",
    "        )\n",
    "\n",
    "class PhaseAwareLSTM(nn.Module):\n",
    "    \"\"\"Streamlined LSTM with phase-aware attention\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Main LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            config['input_size'], config['hidden_size'], config['num_layers'],\n",
    "            batch_first=True, dropout=0.0\n",
    "        )\n",
    "        \n",
    "        # Phase-specific components\n",
    "        attention_dim = config['attention_dim']\n",
    "        self.accel_attention = self._build_attention(config['hidden_size'], attention_dim, config['dropout'])\n",
    "        self.decel_attention = self._build_attention(config['hidden_size'], attention_dim, config['dropout'])\n",
    "        \n",
    "        mid_dim = max(8, config['hidden_size'] // 2)\n",
    "        self.accel_head = self._build_head(config['hidden_size'], mid_dim, config['dropout'])\n",
    "        self.decel_head = self._build_head(config['hidden_size'], mid_dim, config['dropout'])\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _build_attention(self, hidden_size, attention_dim, dropout):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(hidden_size, attention_dim),\n",
    "            nn.LayerNorm(attention_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(attention_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def _build_head(self, hidden_size, mid_dim, dropout):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(hidden_size, mid_dim),\n",
    "            nn.LayerNorm(mid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mid_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            elif 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "                if 'lstm' in name:\n",
    "                    n = param.size(0)\n",
    "                    param.data[(n//4):(n//2)].fill_(1)\n",
    "    \n",
    "    def forward(self, x, relative_speed, current_spacing=None):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # LSTM processing\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Phase detection based on last time step\n",
    "        last_features = x[:, -1, :]\n",
    "        relative_speed_last = last_features[:, 3]\n",
    "        spacing_margin = last_features[:, 4]\n",
    "        \n",
    "        accel_condition = (relative_speed_last > 0.1) | (spacing_margin > 2.0)\n",
    "        decel_condition = (relative_speed_last < -0.1) | (spacing_margin < -1.0)\n",
    "        \n",
    "        # Phase weights [batch_size]\n",
    "        phase_weight = torch.where(\n",
    "            accel_condition, torch.tensor(0.8, device=x.device),\n",
    "            torch.where(decel_condition, torch.tensor(0.2, device=x.device), torch.tensor(0.5, device=x.device))\n",
    "        )\n",
    "        \n",
    "        # Phase-specific processing\n",
    "        accel_attended = self._apply_attention(lstm_out, self.accel_attention)\n",
    "        decel_attended = self._apply_attention(lstm_out, self.decel_attention)\n",
    "        \n",
    "        accel_residual = self.accel_head(accel_attended).squeeze(-1) * self.config['residual_scale']\n",
    "        decel_residual = self.decel_head(decel_attended).squeeze(-1) * self.config['residual_scale']\n",
    "        \n",
    "        # Combine with phase weighting\n",
    "        final_residual = phase_weight * accel_residual + (1 - phase_weight) * decel_residual\n",
    "        \n",
    "        return final_residual, torch.zeros(batch_size, device=x.device)\n",
    "    \n",
    "    def _apply_attention(self, lstm_out, attention_layer):\n",
    "        batch_size, seq_len, hidden_size = lstm_out.size()\n",
    "        reshaped = lstm_out.reshape(batch_size * seq_len, hidden_size)\n",
    "        attention_scores = attention_layer(reshaped).reshape(batch_size, seq_len, 1)\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)\n",
    "        return torch.sum(lstm_out * attention_weights, dim=1)\n",
    "\n",
    "def compute_loss(predicted_acc, real_acc, current_speed, current_spacing, lead_speed, next_real_spacing, dt, \n",
    "                spacing_correction=None, alpha=0.7, beta=0.25, gamma=0.05, model_type='IDM'):\n",
    "    \"\"\"Unified loss computation\"\"\"\n",
    "    # Ensure all tensors are 1D\n",
    "    predicted_acc = ensure_1d_tensor(predicted_acc)\n",
    "    real_acc = ensure_1d_tensor(real_acc)\n",
    "    current_speed = ensure_1d_tensor(current_speed)\n",
    "    current_spacing = ensure_1d_tensor(current_spacing)\n",
    "    lead_speed = ensure_1d_tensor(lead_speed)\n",
    "    next_real_spacing = ensure_1d_tensor(next_real_spacing)\n",
    "    \n",
    "    # OVRV-specific loss\n",
    "    if model_type == 'OVRV':\n",
    "        acc_diff = predicted_acc - real_acc\n",
    "        acc_loss = torch.where(torch.abs(acc_diff) < 1.0, 0.5 * acc_diff ** 2, torch.abs(acc_diff) - 0.5).mean()\n",
    "        \n",
    "        pred_next_speed = torch.clamp(current_speed + predicted_acc * dt, min=0)\n",
    "        pred_next_spacing = torch.clamp(current_spacing + (lead_speed - pred_next_speed) * dt, min=0.1)\n",
    "        spacing_loss = F.mse_loss(pred_next_spacing, next_real_spacing)\n",
    "        \n",
    "        consistency_loss = torch.var(predicted_acc) if predicted_acc.numel() > 1 else torch.tensor(0.0, device=predicted_acc.device)\n",
    "        return 0.7 * acc_loss + 0.2 * spacing_loss + 0.1 * consistency_loss\n",
    "    \n",
    "    # IDM loss\n",
    "    acc_loss = F.mse_loss(predicted_acc, real_acc)\n",
    "    \n",
    "    pred_next_speed = torch.clamp(current_speed + predicted_acc * dt, min=0)\n",
    "    pred_next_spacing = torch.clamp(current_spacing + (lead_speed - pred_next_speed) * dt, min=0.1)\n",
    "    spacing_loss = F.mse_loss(pred_next_spacing, next_real_spacing)\n",
    "    \n",
    "    safe_spacing = 2.0 + 1.0 * torch.clamp(pred_next_speed, min=0)\n",
    "    safety_loss = F.relu(safe_spacing - pred_next_spacing).mean()\n",
    "    physics_loss = spacing_loss + 0.1 * safety_loss\n",
    "    \n",
    "    if spacing_correction is not None:\n",
    "        spacing_correction = ensure_1d_tensor(spacing_correction)\n",
    "        corrected_spacing = current_spacing + (lead_speed - pred_next_speed) * dt + spacing_correction\n",
    "        corrected_spacing = torch.clamp(corrected_spacing, min=0.1)\n",
    "        direct_spacing_loss = F.mse_loss(corrected_spacing, next_real_spacing)\n",
    "        physics_loss = 0.7 * physics_loss + 0.3 * direct_spacing_loss\n",
    "    \n",
    "    reg_loss = 0.01 * torch.mean(torch.abs(predicted_acc - real_acc))\n",
    "    total_loss = alpha * acc_loss + beta * physics_loss + gamma * reg_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "def get_loss_weights(epoch, total_epochs, model_type):\n",
    "    \"\"\"Dynamic loss weights\"\"\"\n",
    "    if model_type == 'OVRV':\n",
    "        return (0.95, 0.0, 0.05) if epoch < 40 else (0.8, 0.15, 0.05)\n",
    "    else:\n",
    "        if epoch < 25:\n",
    "            return 0.8, 0.15, 0.05\n",
    "        elif epoch < 50:\n",
    "            return 0.6, 0.3, 0.1\n",
    "        else:\n",
    "            return 0.4, 0.5, 0.1\n",
    "\n",
    "class TrainingManager:\n",
    "    \"\"\"Streamlined training manager\"\"\"\n",
    "    def __init__(self, train_data, val_data, traditional_model, delta_t, seq_length=12, device='cpu'):\n",
    "        self.device = device\n",
    "        self.traditional_model = traditional_model\n",
    "        self.delta_t = delta_t\n",
    "        \n",
    "        model_type = 'OVRV' if 'OVRV' in str(traditional_model.__class__.__name__) else 'IDM'\n",
    "        \n",
    "        self.train_dataset = EnhancedDataset(train_data, traditional_model, seq_length, delta_t, device, model_type=model_type)\n",
    "        self.val_dataset = EnhancedDataset(val_data, traditional_model, seq_length, delta_t, device, \n",
    "                                         noise_std=0.0, augment_prob=0.0, model_type=model_type)\n",
    "        self.val_dataset.set_training(False)\n",
    "        \n",
    "        self.train_dataloader = DataLoader(self.train_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "        self.val_dataloader = DataLoader(self.val_dataset, batch_size=8, shuffle=False, drop_last=True)\n",
    "        \n",
    "        print(f\"Train batches: {len(self.train_dataloader)}, Val batches: {len(self.val_dataloader)}\")\n",
    "    \n",
    "    def validate_model(self, model, alpha=0.7, beta=0.25, gamma=0.05, model_type='IDM'):\n",
    "        model.eval()\n",
    "        val_losses, val_spacing_rmses = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_dataloader:\n",
    "                features, current_follow_speed, current_spacing, current_lead_speed, next_real_spacing, real_acceleration = batch\n",
    "                relative_speed = current_lead_speed - current_follow_speed\n",
    "                \n",
    "                acc_residual_predictions, spacing_correction = model(features.contiguous(), relative_speed.contiguous(), current_spacing)\n",
    "                \n",
    "                base_acc_batch = ensure_1d_tensor(self.traditional_model.predict_acceleration(\n",
    "                    current_spacing, current_follow_speed, current_lead_speed))\n",
    "                acc_residual_predictions = ensure_1d_tensor(acc_residual_predictions)\n",
    "                \n",
    "                predicted_acc = torch.clamp(base_acc_batch + acc_residual_predictions, -8.0, 6.0)\n",
    "                \n",
    "                pred_next_speed = torch.clamp(current_follow_speed + predicted_acc * self.delta_t, min=0)\n",
    "                pred_next_spacing = torch.clamp(\n",
    "                    current_spacing + (current_lead_speed - pred_next_speed) * self.delta_t + spacing_correction, min=0.1)\n",
    "                \n",
    "                pred_next_spacing = pred_next_spacing.squeeze() if pred_next_spacing.dim() > 1 else pred_next_spacing\n",
    "                next_real_spacing = next_real_spacing.squeeze() if next_real_spacing.dim() > 1 else next_real_spacing\n",
    "                \n",
    "                min_len = min(pred_next_spacing.size(0), next_real_spacing.size(0))\n",
    "                pred_next_spacing, next_real_spacing = pred_next_spacing[:min_len], next_real_spacing[:min_len]\n",
    "                \n",
    "                val_loss = compute_loss(predicted_acc, real_acceleration, current_follow_speed, current_spacing,\n",
    "                                      current_lead_speed, next_real_spacing, self.delta_t, spacing_correction, \n",
    "                                      alpha, beta, gamma, model_type)\n",
    "                spacing_rmse = torch.sqrt(F.mse_loss(pred_next_spacing, next_real_spacing))\n",
    "                \n",
    "                val_losses.append(val_loss.item())\n",
    "                val_spacing_rmses.append(spacing_rmse.item())\n",
    "        \n",
    "        return np.mean(val_losses), np.mean(val_spacing_rmses)\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"Unified model configuration management\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_hybrid_config(model_name):\n",
    "        \"\"\"Get hybrid model configuration\"\"\"\n",
    "        configs = {\n",
    "            'OVRV': {\n",
    "                'hidden_size': 20, 'num_layers': 2, 'dropout': 0.45, \n",
    "                'residual_scale': 0.06, 'attention_dim': 12, 'model_type': 'OVRV'\n",
    "            },\n",
    "            'IDM': {\n",
    "                'hidden_size': 32, 'num_layers': 2, 'dropout': 0.5, \n",
    "                'residual_scale': 0.12, 'attention_dim': 16, 'model_type': 'IDM'\n",
    "            }\n",
    "        }\n",
    "        return configs.get(model_name, configs['IDM'])\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_training_params(model_type, model_id=0, diversity_factor=0.15):\n",
    "        \"\"\"Get training parameters\"\"\"\n",
    "        base_params = {\n",
    "            'hidden_sizes': [16, 20, 24, 28, 32],\n",
    "            'dropouts': [0.4, 0.45, 0.5, 0.42, 0.48],\n",
    "            'lr_multipliers': [1.0, 0.8, 1.2, 0.9, 1.1]\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'hidden_size': base_params['hidden_sizes'][model_id % 5],\n",
    "            'dropout': base_params['dropouts'][model_id % 5],\n",
    "            'lr_multiplier': base_params['lr_multipliers'][model_id % 5],\n",
    "            'weight_decay_factor': 1 + diversity_factor * model_id\n",
    "        }\n",
    "\n",
    "class SimplifiedEnsembleTrainer:\n",
    "    \"\"\"Simplified ensemble trainer\"\"\"\n",
    "    \n",
    "    def __init__(self, n_models=5, diversity_factor=0.15):\n",
    "        self.n_models = n_models\n",
    "        self.diversity_factor = diversity_factor\n",
    "        self.models = []\n",
    "        self.training_histories = []\n",
    "        self.traditional_model = None\n",
    "    \n",
    "    def train_models(self, train_data, val_data, traditional_model, model_type, delta_t, seq_length=12, device='cpu'):\n",
    "        \"\"\"Hybrid model training interface only\"\"\"\n",
    "        self.traditional_model = traditional_model\n",
    "        \n",
    "        # Only support hybrid models now\n",
    "        trainer = TrainingManager(train_data, val_data, traditional_model, delta_t, seq_length, device)\n",
    "    \n",
    "        print(f\"\\nTraining {model_type} ({'Ensemble' if self.n_models > 1 else 'Single'}) ({self.n_models} model{'s' if self.n_models > 1 else ''})\")\n",
    "        \n",
    "        # Get configuration - only hybrid models\n",
    "        base_config = ModelConfig.get_hybrid_config(model_type)\n",
    "        base_config['input_size'] = 6  # Include traditional model prediction\n",
    "        model_class = PhaseAwareLSTM\n",
    "        \n",
    "        base_config['seq_length'] = seq_length\n",
    "        \n",
    "        # Train models\n",
    "        for i in range(self.n_models):\n",
    "            torch.manual_seed(42 + i * 7)\n",
    "            np.random.seed(42 + i * 7)\n",
    "            \n",
    "            # Get training parameters\n",
    "            train_params = ModelConfig.get_training_params(model_type, i, self.diversity_factor)\n",
    "            config = {**base_config, **train_params}\n",
    "            \n",
    "            # Only hybrid model training\n",
    "            model, history = self._train_hybrid_model(trainer, config, model_class, device, i)\n",
    "            \n",
    "            if model is not None:\n",
    "                self.models.append(model)\n",
    "                self.training_histories.append(history)\n",
    "                print(f\"  Model {i+1}: Early stop at epoch {len(history['train_losses'])}, \"\n",
    "                      f\"Val: {history['best_val_loss']:.4f}\")\n",
    "        \n",
    "        return self.models, self.training_histories\n",
    "    \n",
    "    def _train_hybrid_model(self, trainer, config, model_class, device, model_id):\n",
    "        \"\"\"Train hybrid model\"\"\"\n",
    "        model = model_class(config).to(device)\n",
    "        \n",
    "        lr = 5e-5 * config.get('lr_multiplier', 1.0)\n",
    "        weight_decay = (5e-4 if config['model_type'] == 'OVRV' else 1e-4) * (1 + self.diversity_factor * model_id)\n",
    "        \n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.8, min_lr=1e-7)\n",
    "        \n",
    "        patience = 30 if config['model_type'] == 'OVRV' else 25\n",
    "        early_stopping = SpacingFocusedEarlyStopping(patience=patience, min_delta=1e-3, spacing_weight=0.8 if config['model_type'] == 'OVRV' else 0.6)\n",
    "        \n",
    "        train_losses, val_losses, val_spacing_rmses = [], [], []\n",
    "        best_val_loss, best_model_state = float('inf'), None\n",
    "        max_epochs, accumulation_steps = 250, 2\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            alpha, beta, gamma = get_loss_weights(epoch, max_epochs, config['model_type'])\n",
    "            \n",
    "            model.train()\n",
    "            trainer.train_dataset.set_training(True)\n",
    "            epoch_train_losses = []\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            for i, batch in enumerate(trainer.train_dataloader):\n",
    "                features, current_follow_speed, current_spacing, current_lead_speed, next_real_spacing, real_acceleration = batch\n",
    "                relative_speed = current_lead_speed - current_follow_speed\n",
    "                \n",
    "                acc_residual_predictions, spacing_correction = model(features.contiguous(), relative_speed.contiguous(), current_spacing)\n",
    "                \n",
    "                base_acc_batch = ensure_1d_tensor(self.traditional_model.predict_acceleration(\n",
    "                    current_spacing, current_follow_speed, current_lead_speed))\n",
    "                acc_residual_predictions = ensure_1d_tensor(acc_residual_predictions)\n",
    "                \n",
    "                predicted_acc = torch.clamp(base_acc_batch + acc_residual_predictions, -8.0, 6.0)\n",
    "                \n",
    "                total_loss = compute_loss(predicted_acc, real_acceleration, current_follow_speed, current_spacing,\n",
    "                                        current_lead_speed, next_real_spacing, trainer.delta_t, spacing_correction, \n",
    "                                        alpha, beta, gamma, config['model_type'])\n",
    "                \n",
    "                # L2 regularization\n",
    "                l2_reg = sum(torch.norm(param) for param in model.parameters())\n",
    "                total_loss += 1e-5 * l2_reg\n",
    "                \n",
    "                (total_loss / accumulation_steps).backward()\n",
    "                \n",
    "                if (i + 1) % accumulation_steps == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.3)\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                epoch_train_losses.append(total_loss.item())\n",
    "            \n",
    "            avg_train_loss = np.mean(epoch_train_losses)\n",
    "            train_losses.append(avg_train_loss)\n",
    "            \n",
    "            val_loss, val_spacing_rmse = trainer.validate_model(model, alpha, beta, gamma, config['model_type'])\n",
    "            val_losses.append(val_loss)\n",
    "            val_spacing_rmses.append(val_spacing_rmse)\n",
    "            \n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state = model.state_dict().copy()\n",
    "            \n",
    "            if epoch % 20 == 0:\n",
    "                print(f\"  Epoch {epoch}: Train={avg_train_loss:.4f}, Val={val_loss:.4f}, Spacing={val_spacing_rmse:.4f}\")\n",
    "            \n",
    "            if epoch >= 40 and early_stopping(val_loss, val_spacing_rmse):\n",
    "                break\n",
    "        \n",
    "        if best_model_state is not None:\n",
    "            model.load_state_dict(best_model_state)\n",
    "        \n",
    "        return model, {\n",
    "            'train_losses': train_losses, 'val_losses': val_losses, 'val_spacing_rmses': val_spacing_rmses,\n",
    "            'best_val_loss': best_val_loss, 'config': config\n",
    "        }\n",
    "    \n",
    "    def predict(self, features, relative_speed, current_spacing=None, use_temperature=False):\n",
    "        \"\"\"Unified prediction method\"\"\"\n",
    "        if not self.models:\n",
    "            raise ValueError(\"No trained models in ensemble\")\n",
    "        \n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred, _ = model(features, relative_speed, current_spacing)\n",
    "                if use_temperature and hasattr(model.config, 'model_type') and model.config['model_type'] == 'OVRV':\n",
    "                    pred = pred / 1.2\n",
    "                predictions.append(pred)\n",
    "        \n",
    "        return torch.mean(torch.stack(predictions), dim=0)\n",
    "\n",
    "def evaluate_simulation_unified(model_ensemble, test_data, delta_t, seq_length=12, device='cpu', \n",
    "                               model_type='hybrid', traditional_model=None):\n",
    "    \"\"\"Hybrid simulation evaluation function only\"\"\"\n",
    "    if len(test_data) <= seq_length or not model_ensemble.models:\n",
    "        return None\n",
    "    \n",
    "    # Only support hybrid model evaluation\n",
    "    return _evaluate_hybrid_simulation(model_ensemble, test_data, traditional_model, delta_t, seq_length, device)\n",
    "\n",
    "def _evaluate_hybrid_simulation(ensemble_trainer, test_data, traditional_model, delta_t, seq_length, device):\n",
    "    \"\"\"Hybrid model simulation evaluation\"\"\"\n",
    "    eval_data = test_data.iloc[seq_length:].reset_index(drop=True)\n",
    "    n = len(eval_data)\n",
    "    \n",
    "    # Initialize arrays\n",
    "    traditional_acc = np.zeros(n)\n",
    "    hybrid_acc = np.zeros(n)\n",
    "    traditional_speed = np.zeros(n)\n",
    "    hybrid_speed = np.zeros(n)\n",
    "    traditional_spacing = np.zeros(n)\n",
    "    hybrid_spacing = np.zeros(n)\n",
    "    \n",
    "    # Initial conditions\n",
    "    traditional_current_speed = test_data['follow_speed'].iloc[seq_length]\n",
    "    traditional_current_spacing = test_data['spacing'].iloc[seq_length]\n",
    "    hybrid_current_speed = test_data['follow_speed'].iloc[seq_length]\n",
    "    hybrid_current_spacing = test_data['spacing'].iloc[seq_length]\n",
    "    \n",
    "    # Build initial history buffer\n",
    "    history_buffer = []\n",
    "    for i in range(seq_length):\n",
    "        lead_speed = test_data['lead_speed'].iloc[i]\n",
    "        follow_speed = test_data['follow_speed'].iloc[i]\n",
    "        spacing = test_data['spacing'].iloc[i]\n",
    "        relative_speed = lead_speed - follow_speed\n",
    "        \n",
    "        try:\n",
    "            base_acc_i = traditional_model.predict_acceleration(spacing, follow_speed, lead_speed)\n",
    "            base_acc_i = base_acc_i.item() if base_acc_i.dim() > 0 else base_acc_i\n",
    "        except:\n",
    "            base_acc_i = 0.0\n",
    "        \n",
    "        safe_distance = 2.0 + 1.5 * max(follow_speed, 0)\n",
    "        safety_margin = (spacing - safe_distance) / max(safe_distance, 1e-6)\n",
    "        safety_margin = min(max(safety_margin, -5.0), 8.0)\n",
    "        \n",
    "        features = [lead_speed, follow_speed, spacing, relative_speed, safety_margin, float(base_acc_i)]\n",
    "        history_buffer.append(features)\n",
    "    \n",
    "    model_type = 'OVRV' if isinstance(traditional_model, OVRVModel) else 'IDM'\n",
    "    use_temperature = (model_type == 'OVRV')\n",
    "    \n",
    "    # Simulation loop\n",
    "    with torch.no_grad():\n",
    "        for i in range(n):\n",
    "            lead_speed = eval_data['lead_speed'].iloc[i]\n",
    "            \n",
    "            # Traditional model prediction\n",
    "            try:\n",
    "                trad_acc = traditional_model.predict_acceleration(traditional_current_spacing, traditional_current_speed, lead_speed)\n",
    "                trad_acc = trad_acc.item() if trad_acc.dim() > 0 else trad_acc\n",
    "            except:\n",
    "                trad_acc = 0.0\n",
    "            \n",
    "            traditional_acc[i] = float(trad_acc)\n",
    "            traditional_speed[i] = traditional_current_speed\n",
    "            traditional_spacing[i] = traditional_current_spacing\n",
    "            traditional_current_speed = max(0, traditional_current_speed + float(trad_acc) * delta_t)\n",
    "            traditional_current_spacing = max(0.1, traditional_current_spacing + (lead_speed - traditional_current_speed) * delta_t)\n",
    "            \n",
    "            # Hybrid model prediction\n",
    "            try:\n",
    "                current_base_acc = traditional_model.predict_acceleration(hybrid_current_spacing, hybrid_current_speed, lead_speed)\n",
    "                current_base_acc = current_base_acc.item() if current_base_acc.dim() > 0 else current_base_acc\n",
    "            except:\n",
    "                current_base_acc = 0.0\n",
    "            \n",
    "            relative_speed = lead_speed - hybrid_current_speed\n",
    "            safe_distance = 2.0 + 1.5 * max(hybrid_current_speed, 0)\n",
    "            safety_margin = (hybrid_current_spacing - safe_distance) / max(safe_distance, 1e-6)\n",
    "            safety_margin = min(max(safety_margin, -5.0), 8.0)\n",
    "            \n",
    "            current_features = [lead_speed, hybrid_current_speed, hybrid_current_spacing, \n",
    "                               relative_speed, safety_margin, float(current_base_acc)]\n",
    "            history_buffer.append(current_features)\n",
    "            \n",
    "            if len(history_buffer) > seq_length:\n",
    "                history_buffer.pop(0)\n",
    "            \n",
    "            if len(history_buffer) == seq_length:\n",
    "                features_tensor = torch.tensor(history_buffer, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "                relative_speed_tensor = torch.tensor([relative_speed], dtype=torch.float32, device=device)\n",
    "                current_spacing_tensor = torch.tensor([hybrid_current_spacing], dtype=torch.float32, device=device)\n",
    "                \n",
    "                residual = ensemble_trainer.predict(features_tensor, relative_speed_tensor, current_spacing_tensor, use_temperature)\n",
    "                residual = residual.item() if residual.dim() > 0 else residual\n",
    "                hybrid_acc_i = min(max(float(current_base_acc) + residual, -8.0), 6.0)\n",
    "            else:\n",
    "                hybrid_acc_i = float(current_base_acc)\n",
    "            \n",
    "            hybrid_acc[i] = hybrid_acc_i\n",
    "            hybrid_speed[i] = hybrid_current_speed\n",
    "            hybrid_spacing[i] = hybrid_current_spacing\n",
    "            hybrid_current_speed = max(0, hybrid_current_speed + hybrid_acc_i * delta_t)\n",
    "            hybrid_current_spacing = max(0.1, hybrid_current_spacing + (lead_speed - hybrid_current_speed) * delta_t)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    actual_acc = eval_data['actual_acc'].values\n",
    "    actual_speed = eval_data['follow_speed'].values\n",
    "    actual_spacing = eval_data['spacing'].values\n",
    "    \n",
    "    traditional_acc_rmse = np.sqrt(np.mean((traditional_acc - actual_acc) ** 2))\n",
    "    traditional_speed_rmse = np.sqrt(np.mean((traditional_speed - actual_speed) ** 2))\n",
    "    traditional_spacing_rmse = np.sqrt(np.mean((traditional_spacing - actual_spacing) ** 2))\n",
    "    hybrid_acc_rmse = np.sqrt(np.mean((hybrid_acc - actual_acc) ** 2))\n",
    "    hybrid_speed_rmse = np.sqrt(np.mean((hybrid_speed - actual_speed) ** 2))\n",
    "    hybrid_spacing_rmse = np.sqrt(np.mean((hybrid_spacing - actual_spacing) ** 2))\n",
    "    \n",
    "    # Calculate improvements\n",
    "    acc_improvement = (traditional_acc_rmse - hybrid_acc_rmse) / traditional_acc_rmse * 100 if traditional_acc_rmse > 0 else 0\n",
    "    speed_improvement = (traditional_speed_rmse - hybrid_speed_rmse) / traditional_speed_rmse * 100 if traditional_speed_rmse > 0 else 0\n",
    "    spacing_improvement = (traditional_spacing_rmse - hybrid_spacing_rmse) / traditional_spacing_rmse * 100 if traditional_spacing_rmse > 0 else 0\n",
    "    \n",
    "    print(f\"{traditional_model.__class__.__name__} Simulation: Acc {hybrid_acc_rmse:.4f} ({acc_improvement:+.1f}%), \"\n",
    "          f\"Spacing {hybrid_spacing_rmse:.4f} ({spacing_improvement:+.1f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'time': eval_data['time'].values,\n",
    "        'actual_acc': actual_acc,\n",
    "        'actual_speed': actual_speed,\n",
    "        'actual_spacing': actual_spacing,\n",
    "        'traditional_acc': traditional_acc,\n",
    "        'traditional_speed': traditional_speed,\n",
    "        'traditional_spacing': traditional_spacing,\n",
    "        'hybrid_acc': hybrid_acc,\n",
    "        'hybrid_speed': hybrid_speed,\n",
    "        'hybrid_spacing': hybrid_spacing,\n",
    "        'traditional_acc_rmse': traditional_acc_rmse,\n",
    "        'traditional_speed_rmse': traditional_speed_rmse,\n",
    "        'traditional_spacing_rmse': traditional_spacing_rmse,\n",
    "        'hybrid_acc_rmse': hybrid_acc_rmse,\n",
    "        'hybrid_speed_rmse': hybrid_speed_rmse,\n",
    "        'hybrid_spacing_rmse': hybrid_spacing_rmse,\n",
    "        'acc_improvement': acc_improvement,\n",
    "        'speed_improvement': speed_improvement,\n",
    "        'spacing_improvement': spacing_improvement,\n",
    "        'n_models': len(ensemble_trainer.models)\n",
    "    }\n",
    "\n",
    "def save_comprehensive_simulation_csv(ovrv_result, idm_result, dataset_name, output_dir, is_train=False):\n",
    "    \"\"\"Save all simulation results to one comprehensive CSV file\"\"\"\n",
    "    if ovrv_result is None or idm_result is None:\n",
    "        return\n",
    "    \n",
    "    time_axis = ovrv_result['time'] - ovrv_result['time'][0]\n",
    "    \n",
    "    columns = {\n",
    "        'Time': time_axis,\n",
    "        'Actual_Acc': ovrv_result['actual_acc'],\n",
    "        'Actual_Speed': ovrv_result['actual_speed'], \n",
    "        'Actual_Spacing': ovrv_result['actual_spacing'],\n",
    "        'OVRV_Traditional_Acc': ovrv_result['traditional_acc'],\n",
    "        'OVRV_Traditional_Speed': ovrv_result['traditional_speed'],\n",
    "        'OVRV_Traditional_Spacing': ovrv_result['traditional_spacing'],\n",
    "        'OVRV_AI_Correction_Acc': ovrv_result['hybrid_acc'],\n",
    "        'OVRV_AI_Correction_Speed': ovrv_result['hybrid_speed'],\n",
    "        'OVRV_AI_Correction_Spacing': ovrv_result['hybrid_spacing'],\n",
    "        'IDM_Traditional_Acc': idm_result['traditional_acc'],\n",
    "        'IDM_Traditional_Speed': idm_result['traditional_speed'],\n",
    "        'IDM_Traditional_Spacing': idm_result['traditional_spacing'],\n",
    "        'IDM_AI_Correction_Acc': idm_result['hybrid_acc'],\n",
    "        'IDM_AI_Correction_Speed': idm_result['hybrid_speed'],\n",
    "        'IDM_AI_Correction_Spacing': idm_result['hybrid_spacing']\n",
    "    }\n",
    "    \n",
    "    simulation_data = pd.DataFrame(columns)\n",
    "    suffix = \"_train\" if is_train else \"_test\"\n",
    "    csv_path = os.path.join(output_dir, f'{dataset_name}{suffix}_comprehensive_simulation_data.csv')\n",
    "    simulation_data.to_csv(csv_path, index=False)\n",
    "    print(f\"Comprehensive simulation data saved to: {csv_path}\")\n",
    "\n",
    "def preprocess_data(data, skip_warmup=1000, skip_ending=2000, max_rows=20000):\n",
    "    \"\"\"Enhanced data preprocessing\"\"\"\n",
    "    if len(data) < skip_warmup + skip_ending + 100:\n",
    "        raise ValueError(f\"Data length {len(data)} too short\")\n",
    "    \n",
    "    # Extract data range\n",
    "    end_idx = len(data) - skip_ending if skip_ending > 0 else len(data)\n",
    "    start_idx = min(skip_warmup, end_idx - max_rows)\n",
    "    end_idx = min(start_idx + max_rows, end_idx)\n",
    "    data = data.iloc[start_idx:end_idx].copy()\n",
    "    print(f\"Using data range [{start_idx}:{end_idx}]: {len(data)} points\")\n",
    "    \n",
    "    # Data cleaning\n",
    "    data = data.dropna()\n",
    "    data = data[(data['follow_speed'] >= 0) & (data['lead_speed'] >= 0)]\n",
    "    data = data[(data['spacing'] > 0.5) & (data['spacing'] < 150)]\n",
    "    \n",
    "    # Remove outliers\n",
    "    speed_99th = data[['follow_speed', 'lead_speed']].quantile(0.99).max()\n",
    "    data = data[data['follow_speed'] <= speed_99th]\n",
    "    data = data[data['lead_speed'] <= speed_99th]\n",
    "    \n",
    "    # Convert to m/s and calculate acceleration\n",
    "    data[['follow_speed', 'lead_speed']] *= 5/18\n",
    "    delta_t = data['time'].diff().median()\n",
    "    if pd.isna(delta_t) or delta_t <= 0:\n",
    "        delta_t = 0.1\n",
    "        print(\"Warning: Invalid delta_t, defaulting to 0.1\")\n",
    "    \n",
    "    data['actual_acc'] = data['follow_speed'].diff() / delta_t\n",
    "    data['actual_acc'] = data['actual_acc'].clip(-10, 10)\n",
    "    data = data.dropna()\n",
    "    \n",
    "    if len(data) < 100:\n",
    "        raise ValueError(f\"Insufficient data after preprocessing: {len(data)} points\")\n",
    "    \n",
    "    print(f\"Processed points: {len(data)}\")\n",
    "    return data, delta_t\n",
    "\n",
    "def split_data(data, train_ratio=0.6, val_ratio=0.25, test_ratio=0.15):\n",
    "    \"\"\"Split data into train, validation, and test sets\"\"\"\n",
    "    n = len(data)\n",
    "    train_end = int(n * train_ratio)\n",
    "    val_end = int(n * (train_ratio + val_ratio))\n",
    "    \n",
    "    train_data = data.iloc[:train_end].copy()\n",
    "    val_data = data.iloc[train_end:val_end].copy()\n",
    "    test_data = data.iloc[val_end:].copy()\n",
    "    \n",
    "    print(f\"Data split - Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"Data loading and preprocessing\"\"\"\n",
    "    data = pd.read_csv(file_path)\n",
    "    required_cols = ['Time', 'Smooth Speed Follower', 'Smooth Speed Leader', 'Spacing']\n",
    "    data = data[required_cols].rename(columns={\n",
    "        'Time': 'time', 'Smooth Speed Follower': 'follow_speed', \n",
    "        'Smooth Speed Leader': 'lead_speed', 'Spacing': 'spacing'\n",
    "    })\n",
    "    return preprocess_data(data, skip_warmup=1000, skip_ending=2000, max_rows=20000)\n",
    "\n",
    "def plot_training_curves_unified(models_and_histories, dataset_name, output_dir):\n",
    "    \"\"\"Training curves plotting - OVRV and IDM only\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    model_info = [\n",
    "        ('ovrv', 'OVRV Ensemble Training', 'OVRV Model'),\n",
    "        ('idm', 'IDM Ensemble Training', 'IDM Model')\n",
    "    ]\n",
    "    \n",
    "    for idx, (model_key, title, label_prefix) in enumerate(model_info):\n",
    "        if model_key in models_and_histories:\n",
    "            _, histories = models_and_histories[model_key]\n",
    "            for i, hist in enumerate(histories):\n",
    "                axes[idx].plot(hist['train_losses'], f'C{i}-', alpha=0.7, label=f'{label_prefix} {i+1} Train')\n",
    "                axes[idx].plot(hist['val_losses'], f'C{i}--', alpha=0.7, label=f'{label_prefix} {i+1} Val')\n",
    "            \n",
    "            axes[idx].set_title(title)\n",
    "            axes[idx].set_ylabel('Loss')\n",
    "            axes[idx].set_xlabel('Epoch')\n",
    "            axes[idx].legend()\n",
    "            axes[idx].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(output_dir, f'{dataset_name}_training_curves.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Training curves saved: {save_path}\")\n",
    "\n",
    "def plot_simulation_results_unified(results, dataset_name, output_dir, is_train=False):\n",
    "    \"\"\"Simulation results plotting - OVRV and IDM only\"\"\"\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(12, 12))\n",
    "    \n",
    "    for col, (title_prefix, result_key) in enumerate([('OVRV', 'ovrv'), ('IDM', 'idm')]):\n",
    "        if result_key not in results or results[result_key] is None:\n",
    "            continue\n",
    "            \n",
    "        result = results[result_key]\n",
    "        time_axis = result['time']\n",
    "        if not is_train:\n",
    "            time_axis = time_axis - time_axis[0]\n",
    "        \n",
    "        metrics = [\n",
    "            ('Acceleration', 'acc', 'Acceleration (m/sÂ²)'),\n",
    "            ('Speed', 'speed', 'Speed (m/s)'),\n",
    "            ('Spacing', 'spacing', 'Spacing (m)')\n",
    "        ]\n",
    "        \n",
    "        for row, (metric_name, metric_key, ylabel) in enumerate(metrics):\n",
    "            ax = axes[row, col]\n",
    "            \n",
    "            # Actual values\n",
    "            ax.plot(time_axis, result[f'actual_{metric_key}'], 'k-', \n",
    "                   label='Actual ' + metric_name, linewidth=2)\n",
    "            \n",
    "            # Traditional model\n",
    "            ax.plot(time_axis, result[f'traditional_{metric_key}'], 'r--', \n",
    "                   label=f'{title_prefix} (RMSE: {result[f\"traditional_{metric_key}_rmse\"]:.4f})', linewidth=2)\n",
    "            \n",
    "            # AI correction\n",
    "            ax.plot(time_axis, result[f'hybrid_{metric_key}'], 'b-', \n",
    "                   label=f'AI Correction (RMSE: {result[f\"hybrid_{metric_key}_rmse\"]:.4f})', linewidth=2)\n",
    "            \n",
    "            ax.set_title(f'{title_prefix}: {metric_name}')\n",
    "            ax.set_ylabel(ylabel)\n",
    "            if row == 2:\n",
    "                ax.set_xlabel('Time (s)')\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    suffix = \"_train_simulation\" if is_train else \"_test_simulation\"\n",
    "    save_path = os.path.join(output_dir, f'{dataset_name}{suffix}.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"{'Train' if is_train else 'Test'} simulation plot saved: {save_path}\")\n",
    "\n",
    "def print_final_summary(models_and_histories, test_results):\n",
    "    \"\"\"Print final summary - hybrid models only\"\"\"\n",
    "    print(f\"\\n=== FINAL SUMMARY ===\")\n",
    "    \n",
    "    for model_name, (_, histories) in models_and_histories.items():\n",
    "        if histories:\n",
    "            val_losses = [hist['best_val_loss'] for hist in histories]\n",
    "            min_loss = min(val_losses)\n",
    "            \n",
    "            if model_name in test_results and test_results[model_name]:\n",
    "                spacing_improvement = test_results[model_name]['spacing_improvement']\n",
    "                print(f\"{model_name.upper()}: Val Loss {min_loss:.4f}, Test Spacing {spacing_improvement:+.1f}%\")\n",
    "    \n",
    "    print(f\"Hybrid model simulation completed successfully!\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Simplified main function\"\"\"\n",
    "    set_global_seed(42)\n",
    "    \n",
    "    # Setup directories\n",
    "    base_dir = r\"C:\\Users\\yliu117\\Desktop\\CarFollowing_Results\"\n",
    "    output_dir = os.path.join(base_dir, f\"StreamlinedEnsemble_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # Initialize results variable\n",
    "    test_results = {}\n",
    "    \n",
    "    # Dataset configuration\n",
    "    dataset_config = {\n",
    "        'short_55': {\n",
    "            'path': r'C:\\Users\\yliu117\\Desktop\\EV\\EV-ACC data\\combined\\short_55.csv',\n",
    "            'ovrv_params': {'k1': 0.0717, 'k2': 0.6541, 'eta': 17.9107, 'tau': 0.5452},\n",
    "            'idm_params': {'a': 1.6932, 'b': 10.0000, 'delta': 5.0000, 's0': 6.0000, 'T': 1.0325, 'v0': 40.0000}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for dataset_name, config in dataset_config.items():\n",
    "        print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "        \n",
    "        # Data loading and preprocessing\n",
    "        try:\n",
    "            data, delta_t = load_and_preprocess_data(config['path'])\n",
    "        except Exception as e:\n",
    "            print(f\"Data loading failed: {e}\")\n",
    "            continue\n",
    "        \n",
    "        train_data, val_data, test_data = split_data(data, 0.6, 0.25, 0.15)\n",
    "        \n",
    "        # Initialize traditional models\n",
    "        ovrv_model = OVRVModel(**config['ovrv_params'])\n",
    "        idm_model = IDMModel(**config['idm_params'])\n",
    "        \n",
    "        # Train hybrid models only\n",
    "        models_and_histories = {}\n",
    "        \n",
    "        # OVRV ensemble\n",
    "        ovrv_trainer = SimplifiedEnsembleTrainer(n_models=5, diversity_factor=0.15)\n",
    "        models_and_histories['ovrv'] = ovrv_trainer.train_models(\n",
    "            train_data, val_data, ovrv_model, 'OVRV', delta_t, 12, device)\n",
    "        \n",
    "        # IDM ensemble\n",
    "        idm_trainer = SimplifiedEnsembleTrainer(n_models=5, diversity_factor=0.15)\n",
    "        models_and_histories['idm'] = idm_trainer.train_models(\n",
    "            train_data, val_data, idm_model, 'IDM', delta_t, 12, device)\n",
    "        \n",
    "        # Plot training curves\n",
    "        plot_training_curves_unified(models_and_histories, dataset_name, output_dir)\n",
    "        \n",
    "        # Evaluate and plot results\n",
    "        for is_train, data_split in [(True, train_data), (False, test_data)]:\n",
    "            # Hybrid model evaluation\n",
    "            results = {}\n",
    "            results['ovrv'] = evaluate_simulation_unified(\n",
    "                ovrv_trainer, data_split, delta_t, 12, device, 'hybrid', ovrv_model)\n",
    "            results['idm'] = evaluate_simulation_unified(\n",
    "                idm_trainer, data_split, delta_t, 12, device, 'hybrid', idm_model)\n",
    "            \n",
    "            # Save test results for final summary\n",
    "            if not is_train:\n",
    "                test_results = results\n",
    "            \n",
    "            # Plot results\n",
    "            plot_simulation_results_unified(results, dataset_name, output_dir, is_train)\n",
    "            \n",
    "            # Save comprehensive CSV\n",
    "            save_comprehensive_simulation_csv(\n",
    "                results['ovrv'], results['idm'], dataset_name, output_dir, is_train)\n",
    "        \n",
    "        # Print summary\n",
    "        print_final_summary(models_and_histories, test_results)\n",
    "        print(f\"Results saved to: {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
